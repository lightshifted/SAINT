{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3731ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from einops import rearrange\n",
    "from typing import List, Dict, Union\n",
    "from argparse import Namespace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import einsum\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from operations.data import generate_dataset\n",
    "from operations.data import generate_dataloader\n",
    "from operations.embeds import Embedding\n",
    "from operations.model import NewGELU\n",
    "from operations.utils import generate_splits\n",
    "from operations.utils import preprocess\n",
    "from operations.utils import CutMix, Mixup\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46338499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary for configuration settings\n",
    "config = Namespace()\n",
    "\n",
    "# where to store our train/val/test sets\n",
    "config.train_csv_path = 'data/train/target/train_targets.csv'\n",
    "config.train_y_csv_path = 'data/train/label/train_labels.csv'\n",
    "\n",
    "config.val_csv_path = 'data/val/target/val_targets.csv'\n",
    "config.val_y_csv_path = 'data/val/label/val_labels.csv'\n",
    "\n",
    "config.test_csv_path = 'data/test/target/test_targets.csv'\n",
    "config.test_y_csv_path = 'data/test/label/test_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2353d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "data = pd.read_csv('data/creditcard.csv')\n",
    "\n",
    "# generate split indices\n",
    "sup_train_indices, val_indices, test_indices, ssl_train_indices = generate_splits(data.shape[0])\n",
    "\n",
    "# preprocess data\n",
    "df_proc, y_proc, no_num, no_cat, cats = preprocess(data.drop(columns=['Class']), data.Class, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "105571f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate train/val/test sets\n",
    "train_df, train_y = df_proc.iloc[sup_train_indices], y_proc.iloc[sup_train_indices]\n",
    "val_df, val_y = df_proc.iloc[val_indices], y_proc.iloc[val_indices]\n",
    "test_df, test_y = df_proc.iloc[test_indices], y_proc.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7440d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader reads in files using their designated paths\n",
    "train_dataset, val_dataset, test_dataset = generate_dataset(\n",
    "                                            train_csv_path = config.train_csv_path,\n",
    "                                            val_csv_path = config.val_csv_path,\n",
    "                                            test_csv_path = config.test_csv_path,\n",
    "                                            train_y_csv_path = config.train_y_csv_path,\n",
    "                                            val_y_csv_path = config.val_y_csv_path,\n",
    "                                            test_y_csv_path = config.test_y_csv_path)\n",
    "\n",
    "\n",
    "# prepare our train, validation, and test loaders\n",
    "train_loader, validation_loader, test_loader = generate_dataloader(train_bs=16, \n",
    "                                                                   val_bs=16, \n",
    "                                                                   num_workers=0, \n",
    "                                                                   data_paths=vars(config),\n",
    "                                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "628d918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xi_Pi(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.cut_mix = CutMix(config)\n",
    "        self.mix_up = Mixup(config)\n",
    "        \n",
    "        self.em_1 = Embedding(config.n_embd, config.no_num, config.no_cat, config.cats)\n",
    "        self.em_2 = Embedding(config.n_embd, config.no_num, config.no_cat, config.cats)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # embed batch\n",
    "        pi = self.em_1(x)\n",
    "        # embed cutmixed batch\n",
    "        pi_prime_em = self.em_2(self.cut_mix(x))\n",
    "        # mixup embedded cutmixed batch\n",
    "        pi_prime = self.mix_up(pi_prime_em)\n",
    "        \n",
    "        return pi, pi_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59600f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.n_head = n_head\n",
    "        \n",
    "        self.w_qs = nn.Linear(d_model, n_head * d_k)\n",
    "        self.w_ks = nn.Linear(d_model, n_head * d_k)\n",
    "        self.w_vs = nn.Linear(d_model, n_head * d_v)\n",
    "        \n",
    "        nn.init.normal_(self.w_qs.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_k)))\n",
    "        nn.init.normal_(self.w_ks.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_k)))\n",
    "        nn.init.normal_(self.w_vs.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_v)))\n",
    "        \n",
    "        self.fc = nn.Linear(n_head * d_v, d_model)\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        residual = q\n",
    "        q = rearrange(self.w_qs(q), 'b l (head k) -> head b l k', head=self.n_head)\n",
    "        k = rearrange(self.w_ks(k), 'b t (head k) -> head b t k', head=self.n_head)\n",
    "        v = rearrange(self.w_vs(v), 'b t (head v) -> head b t v', head=self.n_head)\n",
    "        attn = torch.einsum('hblk,hbtk->hblt', [q, k]) / np.sqrt(q.shape[-1])\n",
    "        if mask is not None:\n",
    "            attn = attn.masked_fill(mask[None], -np.inf)\n",
    "        attn = torch.softmax(attn, dim=3)\n",
    "        output = torch.einsum('hblt,hbtv->hblv', [attn, v])\n",
    "        output = rearrange(output, 'head b l v -> b l (head v)')\n",
    "        output = self.dropout(self.fc(output))\n",
    "        output = self.layer_norm(output + residual)\n",
    "        return output, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd95c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntersampleAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.d_model = config.d_model\n",
    "        self.n_head = config.n_head\n",
    "        self.d_k = config.d_k\n",
    "        self.d_v = config.d_v\n",
    "        self.h_dim = config.h_dim\n",
    "        \n",
    "        self.to_qkv = nn.Linear(self.h_dim, 3 * self.h_dim) # [(B, T, 3*C)]\n",
    "        self.fc = nn.Linear(self.h_dim, self.h_dim)\n",
    "        \n",
    "        nn.init.normal_(self.to_qkv.weight, mean=0, std=np.sqrt(2.0 / (self.h_dim + self.d_k)))\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        \n",
    "    def attention(self, q, k, v, dropout=None):\n",
    "        d_k = q.size(-1)\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        p_attn = F.softmax(scores, dim = -1)\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    "        output = torch.matmul(p_attn, v)\n",
    "        return output, p_attn          \n",
    "\n",
    "    def intersample(self, q, k, v):\n",
    "        q, k, v = map(lambda x: rearrange(x, 'b w (d h) -> () b h (w d)',h=self.n_head), (q, k, v))\n",
    "        b, h, n, d = q.shape        \n",
    "        output, attn = self.attention(q, k, v)\n",
    "        output = output.squeeze(0)\n",
    "        output = output.reshape(b, h, n, d)\n",
    "        return output\n",
    "        \n",
    "    def forward(self, x):\n",
    "        q, k, v = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        x = self.intersample(q, k, v).view(16, 31, 10)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1de99c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.feed_forward = nn.ModuleDict(dict(\n",
    "            proj_1 = nn.Linear(config.n_embd, 20),\n",
    "            proj_2 = nn.Linear(20, config.n_embd),\n",
    "            dropout = nn.Dropout(0.1),\n",
    "            activation = NewGELU()\n",
    "            ))\n",
    "\n",
    "        m = self.feed_forward\n",
    "\n",
    "        self.mlpf = lambda x: m.proj_2(m.dropout(m.activation(m.proj_1(x))))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.mlpf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d092de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaintPipeline(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.to_qkv = nn.Linear(config.n_embd, 3*config.n_embd)\n",
    "        self.layer_norm = nn.LayerNorm(config.n_embd)\n",
    "        self.multihead_attention = MultiHeadAttention(config.n_head, config.n_embd, config.d_k, config.d_v)\n",
    "        self.FF1 = FeedForward(config)\n",
    "        self.MISA = IntersampleAttention(config)\n",
    "        self.FF2 = FeedForward(config)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        q, k, v = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        output, _ = self.multihead_attention(q, k, v)\n",
    "        # compute multi-head attention\n",
    "        z1 = self.layer_norm(output) + x\n",
    "        z2 = self.layer_norm(self.FF1(z1)) + z1\n",
    "        z2_attn = self.MISA(z2)\n",
    "        z3 = self.layer_norm(z2_attn) + z2\n",
    "        r = self.layer_norm(self.FF2(z3)) + z3\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4304a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection Head\n",
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(config.d_model * config.n_embd, config.dim_head),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        proj_1 = self.mlp(x)\n",
    "        return proj_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8327555",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.proj_1 = MLP(config)\n",
    "        self.proj_2 = MLP(config)\n",
    "        \n",
    "    def forward(self, ri, ri_prime):\n",
    "        ri = ri.reshape(ri.shape[0], -1)\n",
    "        ri_prime = ri_prime.reshape(ri_prime.shape[0], -1)\n",
    "        \n",
    "        zi = self.proj_1(ri)\n",
    "        zi_prime = self.proj_2(ri_prime)\n",
    "        \n",
    "        z_prod = torch.mm(zi, torch.t(zi_prime)) / 0.7\n",
    "        zi_exp = torch.exp(z_prod)\n",
    "        zi_sum = torch.sum(zi_exp, dim=-1, keepdim=True)\n",
    "        z_loss = -1.0 * torch.log(F.relu(torch.diag(zi_exp / zi_sum)) + 1e-7)\n",
    "        return z_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04afb4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.no_num = config.no_num\n",
    "        self.no_cat = config.no_cat\n",
    "        self.cats = config.cats\n",
    "        self.h_dim = config.h_dim\n",
    "        \n",
    "        self.mse = nn.MSELoss()\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.num_loss = 0.0\n",
    "        self.cat_loss = 0.0\n",
    "            \n",
    "    # To-do:\n",
    "    # (1) loss compute for categorical features; add to num. loss for total\n",
    "    # denoising loss\n",
    "            \n",
    "    def forward(self, x, ri_prime):\n",
    "        \n",
    "        # each MLP has a single perceptron layer with a ReLU non-linearity\n",
    "        mlp_cat = nn.ModuleList()\n",
    "        for i in range(1, self.no_cat): # one MLP for each cat. feat.\n",
    "            mlp_cat.append(nn.Sequential(\n",
    "                nn.Linear(self.n_dim, self.cats[i])\n",
    "            ))        \n",
    "        \n",
    "        mlp_cont = nn.ModuleList()\n",
    "        for i in range(1, self.no_num): # one MLP for each cont. feat.\n",
    "            mlp_cont.append(nn.Sequential(\n",
    "                nn.Linear(self.h_dim, 1),\n",
    "                nn.ReLU()\n",
    "            ))\n",
    "        \n",
    "        for idx in range(self.no_num - 1):\n",
    "            ri_proj = mlp_cont[idx](ri_prime[:, idx, :])\n",
    "            xi_feat = x[:, idx]\n",
    "\n",
    "            self.num_loss += self.mse(ri_proj.squeeze().float(), xi_feat.float())\n",
    "                \n",
    "        return self.num_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f49c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#============== Configuration Settings ============\n",
    "config.h_dim = 10\n",
    "config.n_embd = 10\n",
    "config.no_num = no_num\n",
    "config.no_cat = no_cat\n",
    "config.cats = cats\n",
    "config.n_head = 2\n",
    "config.resid_pdrop = 0.8\n",
    "config.prob_cutmix = 0.3 # used in paper\n",
    "config.mixup_alpha = 0.2 # used in paper\n",
    "config.d_k = config.n_embd // config.n_head\n",
    "config.scale = config.n_head ** -0.5\n",
    "config.d_v = 31\n",
    "config.dim_head = 16\n",
    "config.inner_dim = config.n_head * config.dim_head\n",
    "config.d_model = no_num + no_cat\n",
    "config.mask = None\n",
    "config.alpha = 1.0\n",
    "config.attn_pdrop = 0.1\n",
    "config.prob_cutmix = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f928bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embedding = Xi_Pi(config)\n",
    "        self.multihead_attention = MultiHeadAttention(config.n_head, config.n_embd, config.d_k, config.d_v)\n",
    "        self.intersample_attention = IntersampleAttention(config)\n",
    "        self.saint_pipeline = SaintPipeline(config)\n",
    "        self.proj_1 = nn.Sequential(nn.Linear(config.n_embd, config.n_embd), nn.ReLU())\n",
    "        self.proj_2 = nn.Sequential(nn.Linear(config.n_embd, config.n_embd, nn.ReLU()))\n",
    "        self.contrastive_loss = ContrastiveLoss(config)\n",
    "        self.denoising_loss = DenoisingLoss(config)\n",
    "\n",
    "        \n",
    "        self.to_qkv = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pi, pi_prime = self.embedding(x)\n",
    "        query, key, value = self.to_qkv(pi).chunk(3, dim=-1)\n",
    "        output, _ = self.multihead_attention(query, key, value)\n",
    "        output = self.intersample_attention(output)\n",
    "        ri = self.saint_pipeline(pi)\n",
    "        ri_prime = self.saint_pipeline(pi_prime)\n",
    "        zi = self.proj_1(ri).view(ri.size(0), -1)\n",
    "        zi_prime = self.proj_2(ri_prime).view(ri_prime.size(0), -1)\n",
    "        c_loss = self.contrastive_loss(zi, zi_prime)\n",
    "        d_loss = self.denoising_loss(x, ri_prime)\n",
    "        loss = c_loss + d_loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da1494f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device cpu\n",
      "tensor([265.1386, 261.5462, 263.0639, 263.0174, 262.3326, 263.8615, 262.8708,\n",
      "        262.2613, 263.6174, 263.4252, 262.8925, 262.2267, 262.7273, 261.2366,\n",
      "        262.4987, 261.4953], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# backprop and update the parameters\u001b[39;00m\n\u001b[0;32m     32\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 33\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     34\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     36\u001b[0m iter_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\hedronstone\\desktop\\saint\\venv\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\hedronstone\\desktop\\saint\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:166\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    162\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (inputs,) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m \\\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mtuple\u001b[39m(inputs) \u001b[38;5;28;01mif\u001b[39;00m inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[0;32m    165\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[1;32m--> 166\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[1;32mc:\\users\\hedronstone\\desktop\\saint\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:67\u001b[0m, in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 67\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     68\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mones_like(out, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format))\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "# determine the device we'll train on\n",
    "device = 'cpu'\n",
    "\n",
    "max_iters = 100\n",
    "\n",
    "model = Model(config).to(device)\n",
    "print(\"running on device\", device)\n",
    "\n",
    "# variables that will be assigned to trainer class later for logging and etc\n",
    "iter_num = 0.0\n",
    "iter_dt = 0.0\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "model.train()\n",
    "data_iter = iter(train_loader)\n",
    "while True:\n",
    "    try:\n",
    "        batch = next(data_iter)\n",
    "    except StopIteration:\n",
    "        data_iter = iter(train_loader)\n",
    "        batch = next(data_iter)\n",
    "    # place batch onto device\n",
    "    batch = [t.to(device) for t in batch]\n",
    "    x, y = batch\n",
    "    \n",
    "    loss = model(x)\n",
    "    print(loss)\n",
    "    \n",
    "    # backprop and update the parameters\n",
    "    model.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    iter_num += 1\n",
    "    \n",
    "    if max_iters is not None and iter_num >= max_iters:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7565d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacked training loop for development testing\n",
    "lir = []\n",
    "lossi = []\n",
    "stepi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab7bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [ri, ri_prime, zi, zi_prime, contrastive_loss, denoise_loss, t_loss]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    x, y = next(data_iter)\n",
    "    \n",
    "#     # backward pass\n",
    "#     for p in parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab599a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
