{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3731ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from einops import rearrange\n",
    "from typing import List, Dict, Union\n",
    "from argparse import Namespace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import einsum\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from operations.data import generate_dataset\n",
    "from operations.data import generate_dataloader\n",
    "from operations.embeds import Embedding\n",
    "from operations.model import NewGELU\n",
    "from operations.utils import generate_splits\n",
    "from operations.utils import preprocess\n",
    "from operations.utils import CutMix, Mixup\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46338499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary for configuration settings\n",
    "config = Namespace()\n",
    "\n",
    "# where to store our train/val/test sets\n",
    "config.train_csv_path = 'data/train/target/train_targets.csv'\n",
    "config.train_y_csv_path = 'data/train/label/train_labels.csv'\n",
    "\n",
    "config.val_csv_path = 'data/val/target/val_targets.csv'\n",
    "config.val_y_csv_path = 'data/val/label/val_labels.csv'\n",
    "\n",
    "config.test_csv_path = 'data/test/target/test_targets.csv'\n",
    "config.test_y_csv_path = 'data/test/label/test_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2353d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "data = pd.read_csv('data/creditcard.csv')\n",
    "\n",
    "# generate split indices\n",
    "sup_train_indices, val_indices, test_indices, ssl_train_indices = generate_splits(data.shape[0])\n",
    "\n",
    "# preprocess data\n",
    "df_proc, y_proc, no_num, no_cat, cats = preprocess(data.drop(columns=['Class']), data.Class, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "105571f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate train/val/test sets\n",
    "train_df, train_y = df_proc.iloc[sup_train_indices], y_proc.iloc[sup_train_indices]\n",
    "val_df, val_y = df_proc.iloc[val_indices], y_proc.iloc[val_indices]\n",
    "test_df, test_y = df_proc.iloc[test_indices], y_proc.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7440d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader reads in files using their designated paths\n",
    "train_dataset, val_dataset, test_dataset = generate_dataset(\n",
    "                                            train_csv_path = config.train_csv_path,\n",
    "                                            val_csv_path = config.val_csv_path,\n",
    "                                            test_csv_path = config.test_csv_path,\n",
    "                                            train_y_csv_path = config.train_y_csv_path,\n",
    "                                            val_y_csv_path = config.val_y_csv_path,\n",
    "                                            test_y_csv_path = config.test_y_csv_path)\n",
    "\n",
    "\n",
    "# prepare our train, validation, and test loaders\n",
    "train_loader, validation_loader, test_loader = generate_dataloader(train_bs=16, \n",
    "                                                                   val_bs=16, \n",
    "                                                                   num_workers=0, \n",
    "                                                                   data_paths=vars(config),\n",
    "                                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "628d918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xi_Pi(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.cut_mix = CutMix(config)\n",
    "        self.mix_up = Mixup(config)\n",
    "        \n",
    "        self.em_1 = Embedding(config.n_embd, config.no_num, config.no_cat, config.cats)\n",
    "        self.em_2 = Embedding(config.n_embd, config.no_num, config.no_cat, config.cats)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # embed batch\n",
    "        pi = self.em_1(x)\n",
    "        # embed cutmixed batch\n",
    "        pi_prime_em = self.em_2(self.cut_mix(x))\n",
    "        # mixup embedded cutmixed batch\n",
    "        pi_prime = self.mix_up(pi_prime_em)\n",
    "        \n",
    "        return pi, pi_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59600f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.n_head = n_head\n",
    "        \n",
    "        self.w_qs = nn.Linear(d_model, n_head * d_k)\n",
    "        self.w_ks = nn.Linear(d_model, n_head * d_k)\n",
    "        self.w_vs = nn.Linear(d_model, n_head * d_v)\n",
    "        \n",
    "        nn.init.normal_(self.w_qs.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_k)))\n",
    "        nn.init.normal_(self.w_ks.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_k)))\n",
    "        nn.init.normal_(self.w_vs.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_v)))\n",
    "        \n",
    "        self.fc = nn.Linear(n_head * d_v, d_model)\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        residual = q\n",
    "        q = rearrange(self.w_qs(q), 'b l (head k) -> head b l k', head=self.n_head)\n",
    "        k = rearrange(self.w_ks(k), 'b t (head k) -> head b t k', head=self.n_head)\n",
    "        v = rearrange(self.w_vs(v), 'b t (head v) -> head b t v', head=self.n_head)\n",
    "        attn = torch.einsum('hblk,hbtk->hblt', [q, k]) / np.sqrt(q.shape[-1])\n",
    "        if mask is not None:\n",
    "            attn = attn.masked_fill(mask[None], -np.inf)\n",
    "        attn = torch.softmax(attn, dim=3)\n",
    "        output = torch.einsum('hblt,hbtv->hblv', [attn, v])\n",
    "        output = rearrange(output, 'head b l v -> b l (head v)')\n",
    "        output = self.dropout(self.fc(output))\n",
    "        output = self.layer_norm(output + residual)\n",
    "        return output, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd95c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntersampleAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.d_model = config.d_model\n",
    "        self.n_head = config.n_head\n",
    "        self.d_k = config.d_k\n",
    "        self.d_v = config.d_v\n",
    "        self.h_dim = config.h_dim\n",
    "        \n",
    "        self.to_qkv = nn.Linear(self.h_dim, 3 * self.h_dim) # [(B, T, 3*C)]\n",
    "        self.fc = nn.Linear(self.h_dim, self.h_dim)\n",
    "        \n",
    "        nn.init.normal_(self.to_qkv.weight, mean=0, std=np.sqrt(2.0 / (self.h_dim + self.d_k)))\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        \n",
    "    def attention(self, q, k, v, dropout=None):\n",
    "        d_k = q.size(-1)\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        p_attn = F.softmax(scores, dim = -1)\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    "        output = torch.matmul(p_attn, v)\n",
    "        return output, p_attn          \n",
    "\n",
    "    def intersample(self, q, k, v):\n",
    "        q, k, v = map(lambda x: rearrange(x, 'b w (d h) -> () b h (w d)',h=self.n_head), (q, k, v))\n",
    "        b, h, n, d = q.shape        \n",
    "        output, attn = self.attention(q, k, v)\n",
    "        output = output.squeeze(0)\n",
    "        output = output.reshape(b, h, n, d)\n",
    "        return output\n",
    "        \n",
    "    def forward(self, x):\n",
    "        q, k, v = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        x = self.intersample(q, k, v).view(16, 31, 10)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1de99c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.feed_forward = nn.ModuleDict(dict(\n",
    "            proj_1 = nn.Linear(config.n_embd, 20),\n",
    "            proj_2 = nn.Linear(20, config.n_embd),\n",
    "            dropout = nn.Dropout(0.1),\n",
    "            activation = NewGELU()\n",
    "            ))\n",
    "\n",
    "        m = self.feed_forward\n",
    "\n",
    "        self.mlpf = lambda x: m.proj_2(m.dropout(m.activation(m.proj_1(x))))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.mlpf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d092de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaintPipeline(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(config.n_embd)\n",
    "        self.multihead_attention = MultiHeadAttention(config.n_head, config.n_embd, config.d_k, config.d_v)\n",
    "        self.FF1 = FeedForward(config)\n",
    "        self.MISA = IntersampleAttention(config)\n",
    "        self.FF2 = FeedForward(config)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # compute multi-head attention\n",
    "        z1 = self.layer_norm(x) + x\n",
    "        z2 = self.layer_norm(self.FF1(z1)) + z1\n",
    "        z2_attn = self.MISA(z2)\n",
    "        z3 = self.layer_norm(z2_attn) + z2\n",
    "        r = self.layer_norm(self.FF2(z3)) + z3\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4304a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection Head\n",
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(config.d_model * config.n_embd, config.dim_head),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        proj_1 = self.mlp(x)\n",
    "        return proj_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8327555",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.proj_1 = MLP(config)\n",
    "        self.proj_2 = MLP(config)\n",
    "        \n",
    "    def forward(self, ri, ri_prime):\n",
    "        ri = ri.reshape(ri.shape[0], -1)\n",
    "        ri_prime = ri_prime.reshape(ri_prime.shape[0], -1)\n",
    "        \n",
    "        zi = self.proj_1(ri)\n",
    "        zi_prime = self.proj_2(ri_prime)\n",
    "        \n",
    "        z_prod = torch.mm(zi, torch.t(zi_prime)) / 0.7\n",
    "        zi_exp = torch.exp(z_prod)\n",
    "        zi_sum = torch.sum(zi_exp, dim=-1, keepdim=True)\n",
    "        z_loss = -1.0 * torch.log(F.relu(torch.diag(zi_exp / zi_sum)) + 1e-7)\n",
    "        return z_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c8d7d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.no_num = config.no_num\n",
    "        self.no_cat = config.no_cat\n",
    "        self.cats = config.cats\n",
    "        self.h_dim = config.h_dim\n",
    "        \n",
    "        self.mse = nn.MSELoss()\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.num_loss = 0.0\n",
    "        self.cat_loss = 0.0\n",
    "            \n",
    "    # To-do:\n",
    "    # (1) loss compute for categorical features; add to num. loss for total\n",
    "    # denoising loss\n",
    "            \n",
    "    def forward(self, x, ri_prime):\n",
    "        \n",
    "        # each MLP has a single perceptron layer with a ReLU non-linearity\n",
    "        mlp_cat = nn.ModuleList()\n",
    "        for i in range(1, self.no_cat): # one MLP for each cat. feat.\n",
    "            mlp_cat.append(nn.Sequential(\n",
    "                nn.Linear(self.n_dim, self.cats[i])\n",
    "            ))        \n",
    "        \n",
    "        mlp_cont = nn.ModuleList()\n",
    "        for i in range(1, self.no_num): # one MLP for each cont. feat.\n",
    "            mlp_cont.append(nn.Sequential(\n",
    "                nn.Linear(self.h_dim, 1),\n",
    "                nn.ReLU()\n",
    "            ))\n",
    "        \n",
    "        for idx in range(self.no_num - 1):\n",
    "            ri_proj = mlp_cont[idx](ri_prime[:, idx, :])\n",
    "            xi_feat = x[:, idx]\n",
    "\n",
    "            self.num_loss += self.mse(ri_proj.squeeze().float(), xi_feat.float())\n",
    "                \n",
    "        return self.num_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9d8d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#============== Configuration Settings ============\n",
    "config.h_dim = 10\n",
    "config.n_embd = 10\n",
    "config.no_num = no_num\n",
    "config.no_cat = no_cat\n",
    "config.cats = cats\n",
    "config.n_head = 2\n",
    "config.resid_pdrop = 0.8\n",
    "config.prob_cutmix = 0.3 # used in paper\n",
    "config.mixup_alpha = 0.2 # used in paper\n",
    "config.d_k = config.n_embd // config.n_head\n",
    "config.scale = config.n_head ** -0.5\n",
    "config.d_v = 31\n",
    "config.dim_head = 16\n",
    "config.inner_dim = config.n_head * config.dim_head\n",
    "config.d_model = no_num + no_cat\n",
    "config.mask = None\n",
    "config.alpha = 1.0\n",
    "config.attn_pdrop = 0.1\n",
    "config.prob_cutmix = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a48df730",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader)) # (16, 31)\n",
    "\n",
    "xi_pi = Xi_Pi(config)\n",
    "pi, pi_prime = xi_pi(x)\n",
    "\n",
    "msa = MultiHeadAttention(config.n_head, config.n_embd, config.d_k, config.d_v)\n",
    "isa = IntersampleAttention(config)\n",
    "\n",
    "to_qkv = nn.Linear(config.n_embd, 3*config.n_embd)\n",
    "query, key, value = to_qkv(pi).chunk(3, dim=-1)\n",
    "\n",
    "output, _ = msa(query, key, value)\n",
    "ri = isa(output)\n",
    "\n",
    "sp = SaintPipeline(config)\n",
    "\n",
    "ri = sp(pi)\n",
    "ri_prime = sp(pi_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4fa40e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [19], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# denoising loss\u001b[39;00m\n\u001b[0;32m      6\u001b[0m d_loss \u001b[38;5;241m=\u001b[39m DenoisingLoss(config)\n\u001b[1;32m----> 7\u001b[0m denoise_loss \u001b[38;5;241m=\u001b[39m d_loss(x, ri_prime)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# total loss\u001b[39;00m\n\u001b[0;32m     10\u001b[0m t_loss \u001b[38;5;241m=\u001b[39m contrastive_loss \u001b[38;5;241m+\u001b[39m denoise_loss\n",
      "File \u001b[1;32mc:\\users\\hedronstone\\desktop\\saint\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn [13], line 43\u001b[0m, in \u001b[0;36mDenoisingLoss.forward\u001b[1;34m(self, x, ri_prime)\u001b[0m\n\u001b[0;32m     39\u001b[0m     xi_feat \u001b[38;5;241m=\u001b[39m x[:, idx]\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmse(ri_proj\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mfloat(), xi_feat\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnum_loss\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_loss' is not defined"
     ]
    }
   ],
   "source": [
    "# contrastive lostt\n",
    "z_loss = ContrastiveLoss(config)\n",
    "contrastive_loss = z_loss(ri, ri_prime)\n",
    "\n",
    "# denoising loss\n",
    "d_loss = DenoisingLoss(config)\n",
    "denoise_loss = d_loss(x, ri_prime)\n",
    "\n",
    "# total loss\n",
    "t_loss = contrastive_loss + denoise_loss\n",
    "\n",
    "print(\"total loss:\\n\", t_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653937d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
